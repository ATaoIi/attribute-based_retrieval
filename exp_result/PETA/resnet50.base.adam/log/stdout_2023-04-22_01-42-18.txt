BACKBONE:
  MULTISCALE: False
  TYPE: resnet50
CLASSIFIER:
  BN: False
  NAME: linear
  POOLING: avg
  SCALE: 1
  TYPE: base
DATASET:
  HEIGHT: 256
  LABEL: eval
  NAME: PETA
  TARGETTRANSFORM: []
  TEST_SPLIT: test
  TRAIN_SPLIT: trainval
  TYPE: pedes
  VAL_SPLIT: test
  WIDTH: 192
  ZERO_SHOT: False
DISTRIBUTTED: False
INFER:
  SAMPLING: False
LOSS:
  LOSS_WEIGHT: [1]
  SAMPLE_WEIGHT: weight
  SIZESUM: True
  TYPE: bceloss
METRIC:
  TYPE: pedestrian
NAME: resnet50.base.adam
REDIRECTOR: True
RELOAD:
  NAME: backbone
  PTH: 
  TYPE: False
TRAIN:
  AUX_LOSS_START: -1
  BATCH_SIZE: 64
  BN_WD: True
  CLIP_GRAD: True
  DATAAUG:
    AUTOAUG_PROB: 0.5
    TYPE: base
  EMA:
    DECAY: 0.9998
    ENABLE: False
    FORCE_CPU: False
  LR_SCHEDULER:
    LR_FT: 0.0001
    LR_NEW: 0.0001
    LR_STEP: [0]
    TYPE: plateau
    WMUP_COEF: 0.1
  MAX_EPOCH: 30
  NUM_WORKERS: 4
  OPTIMIZER:
    MOMENTUM: 0.9
    TYPE: adam
    WEIGHT_DECAY: 0.0005
  SHUFFLE: True
TRANS:
  DEC_LAYERS: 6
  DIM_FFD: 2048
  DIM_HIDDEN: 256
  DROPOUT: 0.1
  ENC_LAYERS: 6
  EOS_COEF: 0.1
  NHEADS: 8
  NUM_QUERIES: 100
  PRE_NORM: False
VIS:
  CAM: valid
  TENSORBOARD:
    ENABLE: True
  VISDOM: False
Compose(
    Resize(size=(256, 192), interpolation=bilinear, max_size=None, antialias=None)
    Pad(padding=10, fill=0, padding_mode=constant)
    RandomCrop(size=(256, 192), padding=None)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
which pickle ./data\PETA\dataset_all.pkl
trainval target_label: all
which pickle ./data\PETA\dataset_all.pkl
test target_label: all
------------------------------------------------------------
PETA attr_num : 35, eval_attr_num : 35 trainval set: 11400, test set: 7600, 
backbone: resnet50, classifier: linear
model_name: resnet50.base.adam
2023-04-22_01-44-47, Step 99/178 in Ep 0, LR: [1.0e-04, 1.0e-04] Time: 0.57s , train_loss: 21.2948, 
['0.0000']
2023-04-22_01-45-31, Step 177/178 in Ep 0, LR: [1.0e-04, 1.0e-04] Time: 0.51s , train_loss: 19.2627, 
['0.0000']
Epoch 0, LR 0.0001, Train_Time 192.57s, Loss: 19.2627
['0.0000']
Evaluation on train set, train losses 19.2627425033055
 ma: 0.6436, label_f1: 0.4385, pos_recall: 0.4082 , neg_recall: 0.8791 
 Acc: 0.5519, Prec: 0.7400, Rec: 0.6548, F1: 0.6948
Evaluation on test set, valid losses 15.210624823049336
 ma: 0.7193, label_f1: 0.5547, pos_recall: 0.5298 , neg_recall: 0.9087 
 Acc: 0.6510, Prec: 0.7967, Rec: 0.7496, F1: 0.7724
2023-04-22_01-46-04
------------------------------------------------------------
2023-04-22_01-47-14, Step 99/178 in Ep 1, LR: [1.0e-04, 1.0e-04] Time: 0.59s , train_loss: 13.8229, 
['0.0000']
2023-04-22_01-47-59, Step 177/178 in Ep 1, LR: [1.0e-04, 1.0e-04] Time: 0.47s , train_loss: 13.4606, 
['0.0000']
Epoch 1, LR 0.0001, Train_Time 115.18s, Loss: 13.4606
['0.0000']
Evaluation on train set, train losses 13.460608589515257
 ma: 0.7622, label_f1: 0.6353, pos_recall: 0.6039 , neg_recall: 0.9204 
 Acc: 0.6991, Prec: 0.8240, Rec: 0.7898, F1: 0.8066
Evaluation on test set, valid losses 12.631494482024378
 ma: 0.7772, label_f1: 0.6555, pos_recall: 0.6325 , neg_recall: 0.9219 
 Acc: 0.7132, Prec: 0.8286, Rec: 0.8025, F1: 0.8153
2023-04-22_01-48-31
------------------------------------------------------------
2023-04-22_01-49-42, Step 99/178 in Ep 2, LR: [1.0e-04, 1.0e-04] Time: 0.62s , train_loss: 10.9370, 
['0.0000']
2023-04-22_01-50-26, Step 177/178 in Ep 2, LR: [1.0e-04, 1.0e-04] Time: 0.47s , train_loss: 10.9011, 
['0.0000']
Epoch 2, LR 0.0001, Train_Time 114.78s, Loss: 10.9011
['0.0000']
Evaluation on train set, train losses 10.901085349950897
 ma: 0.8099, label_f1: 0.7081, pos_recall: 0.6832 , neg_recall: 0.9367 
 Acc: 0.7592, Prec: 0.8588, Rec: 0.8387, F1: 0.8486
Evaluation on test set, valid losses 11.747020697393337
 ma: 0.8014, label_f1: 0.6932, pos_recall: 0.6781 , neg_recall: 0.9247 
 Acc: 0.7358, Prec: 0.8367, Rec: 0.8218, F1: 0.8292
2023-04-22_01-50-58
------------------------------------------------------------
2023-04-22_01-52-09, Step 99/178 in Ep 3, LR: [1.0e-04, 1.0e-04] Time: 0.59s , train_loss: 9.1733, 
['0.0000']
2023-04-22_01-52-54, Step 177/178 in Ep 3, LR: [1.0e-04, 1.0e-04] Time: 0.48s , train_loss: 9.1757, 
['0.0000']
Epoch 3, LR 0.0001, Train_Time 115.92s, Loss: 9.1757
['0.0000']
Evaluation on train set, train losses 9.175699110781208
 ma: 0.8422, label_f1: 0.7576, pos_recall: 0.7368 , neg_recall: 0.9477 
 Acc: 0.7959, Prec: 0.8810, Rec: 0.8679, F1: 0.8744
Evaluation on test set, valid losses 10.914293850169463
 ma: 0.8182, label_f1: 0.7168, pos_recall: 0.7007 , neg_recall: 0.9357 
 Acc: 0.7492, Prec: 0.8496, Rec: 0.8262, F1: 0.8377
2023-04-22_01-53-26
------------------------------------------------------------
2023-04-22_01-54-37, Step 99/178 in Ep 4, LR: [1.0e-04, 1.0e-04] Time: 0.56s , train_loss: 7.7949, 
['0.0000']
2023-04-22_01-55-21, Step 177/178 in Ep 4, LR: [1.0e-04, 1.0e-04] Time: 0.51s , train_loss: 7.8894, 
['0.0000']
Epoch 4, LR 0.0001, Train_Time 115.01s, Loss: 7.8894
['0.0000']
Evaluation on train set, train losses 7.889402927977316
 ma: 0.8668, label_f1: 0.7941, pos_recall: 0.7780 , neg_recall: 0.9557 
 Acc: 0.8246, Prec: 0.8978, Rec: 0.8899, F1: 0.8938
Evaluation on test set, valid losses 11.1098753103689
 ma: 0.8195, label_f1: 0.7215, pos_recall: 0.7060 , neg_recall: 0.9330 
 Acc: 0.7472, Prec: 0.8449, Rec: 0.8270, F1: 0.8359
2023-04-22_01-55-53
------------------------------------------------------------
